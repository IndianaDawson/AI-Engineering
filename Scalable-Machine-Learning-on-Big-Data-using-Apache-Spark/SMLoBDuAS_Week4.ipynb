{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Welcome to the final project of  \u201cApache Spark for Scalable Machine Learning on BigData\u201d. In this assignment you\u2019ll analyze a real-world dataset and apply machine learning on it using Apache Spark. \n\nIn order to pass, you need to implement some code (as described in the instruction section on Coursera) and finally answer a quiz on the Coursera platform.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This notebook is designed to run in a IBM Watson Studio default runtime (NOT the Watson Studio Apache Spark Runtime as the default runtime with 1 vCPU is free of charge). Therefore, we install Apache Spark in local mode for test purposes only. Please don't use it in production.\n\nIn case you are facing issues, please read the following two documents first:\n\nhttps://github.com/IBM/skillsnetwork/wiki/Environment-Setup\n\nhttps://github.com/IBM/skillsnetwork/wiki/FAQ\n\nThen, please feel free to ask:\n\nhttps://coursera.org/learn/machine-learning-big-data-apache-spark/discussions/all\n\nPlease make sure to follow the guidelines before asking a question:\n\nhttps://github.com/IBM/skillsnetwork/wiki/FAQ#im-feeling-lost-and-confused-please-help-me\n\n\nIf running outside Watson Studio, this should work as well. In case you are running in an Apache Spark context outside Watson Studio, please remove the Apache Spark setup in the first notebook cells."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Part 1"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20200901043949-0003\nKERNEL_ID = 4f5e22ad-3898-4688-bbc8-422e94a01330\n"
                },
                {
                    "data": {
                        "text/markdown": "# <span style=\"color:red\"><<<<<!!!!! It seems that you are running in a IBM Watson Studio Apache Spark Notebook. Please run it in an IBM Watson Studio Default Runtime (without Apache Spark) !!!!!>>>>></span>",
                        "text/plain": "<IPython.core.display.Markdown object>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": "from IPython.display import Markdown, display\ndef printmd(string):\n    display(Markdown('# <span style=\"color:red\">'+string+'</span>'))\n\n\nif ('sc' in locals() or 'sc' in globals()):\n    printmd('<<<<<!!!!! It seems that you are running in a IBM Watson Studio Apache Spark Notebook. Please run it in an IBM Watson Studio Default Runtime (without Apache Spark) !!!!!>>>>>')\n"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting pyspark==2.4.5\nCollecting py4j==0.10.7 (from pyspark==2.4.5)\n  Using cached https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.7 pyspark-2.4.5\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/py4j already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/pyspark-2.4.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/py4j-0.10.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/pyspark already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3.6/share already exists. Specify --upgrade to force replacement.\u001b[0m\n"
                }
            ],
            "source": "!pip install pyspark==2.4.5"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "try:\n    from pyspark import SparkContext, SparkConf\n    from pyspark.sql import SparkSession\nexcept ImportError as e:\n    printmd('<<<<<!!!!! Please restart your kernel after installing Apache Spark !!!!!>>>>>')"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n\nspark = SparkSession \\\n    .builder \\\n    .getOrCreate()"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2020-09-01 04:39:59--  https://github.com/IBM/coursera/raw/master/hmp.parquet\nResolving github.com (github.com)... 140.82.114.3\nConnecting to github.com (github.com)|140.82.114.3|:443... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: https://github.com/IBM/skillsnetwork/raw/master/hmp.parquet [following]\n--2020-09-01 04:39:59--  https://github.com/IBM/skillsnetwork/raw/master/hmp.parquet\nReusing existing connection to github.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/IBM/skillsnetwork/master/hmp.parquet [following]\n--2020-09-01 04:39:59--  https://raw.githubusercontent.com/IBM/skillsnetwork/master/hmp.parquet\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 932997 (911K) [application/octet-stream]\nSaving to: \u2018hmp.parquet\u2019\n\n100%[======================================>] 932,997     --.-K/s   in 0.03s   \n\n2020-09-01 04:39:59 (26.0 MB/s) - \u2018hmp.parquet\u2019 saved [932997/932997]\n\n"
                }
            ],
            "source": "# delete files from previous runs\n!rm -f hmp.parquet*\n\n# download the file containing the data in PARQUET format\n!wget https://github.com/IBM/coursera/raw/master/hmp.parquet\n    \n# create a dataframe out of it\ndf = spark.read.parquet('hmp.parquet')\n\n# register a corresponding query table\ndf.createOrReplaceTempView('df')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Since this is supervised learning, let\u2019s split our data into train (80%) and test (20%) set."
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "splits = df.randomSplit([0.8, 0.2])\ndf_train = splits[0]\ndf_test = splits[1]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Again, we can re-use our feature engineering pipeline"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml.feature import StringIndexer, OneHotEncoder\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import Normalizer\n\n\nindexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n\nvectorAssembler = VectorAssembler(inputCols=[\"x\",\"y\",\"z\"],\n                                  outputCol=\"features\")\n\nnormalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now we use LogisticRegression, a simple and basic linear classifier to obtain a classification performance baseline."
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml import Pipeline\n\nlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\npipeline = Pipeline(stages=[indexer, vectorAssembler, normalizer,lr])\nmodel = pipeline.fit(df_train)\nprediction = model.transform(df_test)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "If we look at the schema of the prediction dataframe we see that there is an additional column called prediction which contains the best guess for the class our model predicts."
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "root\n |-- x: integer (nullable = true)\n |-- y: integer (nullable = true)\n |-- z: integer (nullable = true)\n |-- source: string (nullable = true)\n |-- class: string (nullable = true)\n |-- label: double (nullable = false)\n |-- features: vector (nullable = true)\n |-- features_norm: vector (nullable = true)\n |-- rawPrediction: vector (nullable = true)\n |-- probability: vector (nullable = true)\n |-- prediction: double (nullable = false)\n\n"
                }
            ],
            "source": "prediction.printSchema()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let\u2019s evaluate performance by using a build-in functionality of Apache SparkML."
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.20655419948837575"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nMulticlassClassificationEvaluator().setMetricName(\"accuracy\").evaluate(prediction)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "So we get 20% right. This is not bad for a baseline. Note that random guessing would give us only 7%. Of course we need to improve. You might have notices that we\u2019re dealing with a time series here. And we\u2019re not making use of that fact right now as we look at each training example only individually. But this is ok for now. More advanced courses like \u201cAdvanced Machine Learning and Signal Processing\u201d (https://www.coursera.org/learn/advanced-machine-learning-signal-processing/) will teach you how to improve accuracy to the nearly 100% by using algorithms like Fourier transformation or wavelet transformation. But let\u2019s skip this for now. In the following cell, please use the RandomForest classifier (you might need to play with the \u201cnumTrees\u201d parameter) in the code cell below. You should get an accuracy of around 44%. More on RandomForest can be found here:\n\nhttps://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.4372246075481479"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from pyspark.ml.classification import RandomForestClassifier\n\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)\npipeline = Pipeline(stages=[indexer, vectorAssembler, normalizer,rf])\nmodel = pipeline.fit(df_train)\nprediction = model.transform(df_test)\n\nMulticlassClassificationEvaluator().setMetricName(\"accuracy\").evaluate(prediction)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Project"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let\u2019s start by downloading the dataset and creating a dataframe. This dataset can be found on DAX, the IBM Data Asset Exchange and can be downloaded for free.\n\nhttps://developer.ibm.com/exchanges/data/all/jfk-weather-data/"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2020-09-01 04:41:34--  https://github.com/IBM/skillsnetwork/raw/master/coursera_bd/week4/jfk_weather.tar.gz\nResolving github.com (github.com)... 140.82.114.3\nConnecting to github.com (github.com)|140.82.114.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/IBM/skillsnetwork/master/coursera_bd/week4/jfk_weather.tar.gz [following]\n--2020-09-01 04:41:35--  https://raw.githubusercontent.com/IBM/skillsnetwork/master/coursera_bd/week4/jfk_weather.tar.gz\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.8.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.8.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2575759 (2.5M) [application/octet-stream]\nSaving to: \u2018jfk_weather.tar.gz\u2019\n\n100%[======================================>] 2,575,759   --.-K/s   in 0.06s   \n\n2020-09-01 04:41:35 (42.6 MB/s) - \u2018jfk_weather.tar.gz\u2019 saved [2575759/2575759]\n\n./._jfk_weather.csv\njfk_weather.csv\n"
                }
            ],
            "source": "# delete files from previous runs\n!rm -f jfk_weather*\n\n# download the file containing the data in CSV format\n\n###### make sure to change it to this\n!wget https://github.com/IBM/skillsnetwork/raw/master/coursera_bd/week4/jfk_weather.tar.gz\n########################\n\n# extract the data\n!tar xvfz jfk_weather.tar.gz\n    \n# create a dataframe out of it by using the first row as field names and trying to infer a schema based on contents\ndf = spark.read.option(\"header\", \"true\").option(\"inferSchema\",\"true\").csv('jfk_weather.csv')\n\n# register a corresponding query table\ndf.createOrReplaceTempView('df')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The dataset contains some null values, therefore schema inference didn\u2019t work properly for all columns, in addition, a column contained trailing characters, so we need to clean up the data set first. This is a normal task in any data science project since your data is never clean, don\u2019t worry if you don\u2019t understand all code, you won\u2019t be asked about it. "
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "import random\nrandom.seed(42)\n\nfrom pyspark.sql.functions import translate, col\n\ndf_cleaned = df \\\n    .withColumn(\"HOURLYWindSpeed\", df.HOURLYWindSpeed.cast('double')) \\\n    .withColumn(\"HOURLYWindDirection\", df.HOURLYWindDirection.cast('double')) \\\n    .withColumn(\"HOURLYStationPressure\", translate(col(\"HOURLYStationPressure\"), \"s,\", \"\")) \\\n    .withColumn(\"HOURLYPrecip\", translate(col(\"HOURLYPrecip\"), \"s,\", \"\")) \\\n    .withColumn(\"HOURLYRelativeHumidity\", translate(col(\"HOURLYRelativeHumidity\"), \"*\", \"\")) \\\n    .withColumn(\"HOURLYDRYBULBTEMPC\", translate(col(\"HOURLYDRYBULBTEMPC\"), \"*\", \"\")) \\\n\ndf_cleaned =   df_cleaned \\\n                    .withColumn(\"HOURLYStationPressure\", df_cleaned.HOURLYStationPressure.cast('double')) \\\n                    .withColumn(\"HOURLYPrecip\", df_cleaned.HOURLYPrecip.cast('double')) \\\n                    .withColumn(\"HOURLYRelativeHumidity\", df_cleaned.HOURLYRelativeHumidity.cast('double')) \\\n                    .withColumn(\"HOURLYDRYBULBTEMPC\", df_cleaned.HOURLYDRYBULBTEMPC.cast('double')) \\\n\ndf_filtered = df_cleaned.filter(\"\"\"\n    HOURLYWindSpeed <> 0\n    and HOURLYWindSpeed IS NOT NULL\n    and HOURLYWindDirection IS NOT NULL\n    and HOURLYStationPressure IS NOT NULL\n    and HOURLYPressureTendency IS NOT NULL\n    and HOURLYPrecip IS NOT NULL\n    and HOURLYRelativeHumidity IS NOT NULL\n    and HOURLYDRYBULBTEMPC IS NOT NULL\n\"\"\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We want to predict the value of one column based of some others. It is sometimes helpful to print a correlation matrix. "
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[ 1.        ,  0.25478863, -0.26171147],\n       [ 0.25478863,  1.        , -0.13377466],\n       [-0.26171147, -0.13377466,  1.        ]])"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from pyspark.ml.feature import VectorAssembler\nvectorAssembler = VectorAssembler(inputCols=[\"HOURLYWindSpeed\",\"HOURLYWindDirection\",\"HOURLYStationPressure\"],\n                                  outputCol=\"features\")\ndf_pipeline = vectorAssembler.transform(df_filtered)\nfrom pyspark.ml.stat import Correlation\nCorrelation.corr(df_pipeline,\"features\").head()[0].toArray()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As we can see, HOURLYWindSpeed and HOURLYWindDirection correlate with 0.25478863 whereas HOURLYWindSpeed  and HOURLYStationPressure correlate with -0.26171147, this is a good sign if we want to predict HOURLYWindSpeed from HOURLYWindDirection and HOURLYStationPressure. Note that the numbers can change over time as we are always working with the latest data.\nSince this is supervised learning, let\u2019s split our data into train (80%) and test (20%) set."
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": "splits = df_filtered.randomSplit([0.8, 0.2])\ndf_train = splits[0]\ndf_test = splits[1]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Again, we can re-use our feature engineering pipeline"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml.feature import StringIndexer, OneHotEncoder\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import Normalizer\nfrom pyspark.ml import Pipeline\n\nvectorAssembler = VectorAssembler(inputCols=[\n                                    \"HOURLYWindDirection\",\n                                    \"ELEVATION\",\n                                    \"HOURLYStationPressure\"],\n                                  outputCol=\"features\")\n\nnormalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now we define a function for evaluating our regression prediction performance. We\u2019re using RMSE (Root Mean Squared Error) here , the smaller the better\u2026\n\n"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": "def regression_metrics(prediction):\n    from pyspark.ml.evaluation import RegressionEvaluator\n    evaluator = RegressionEvaluator(\n    labelCol=\"HOURLYWindSpeed\", predictionCol=\"prediction\", metricName=\"rmse\")\n    rmse = evaluator.evaluate(prediction)\n    print(\"RMSE on test data = %g\" % rmse)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let\u2019s run a linear regression model first for building a baseline.\n\n"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "RMSE on test data = 5.30775\n"
                }
            ],
            "source": "#LR1\n\nfrom pyspark.ml.regression import LinearRegression\n\n\nlr = LinearRegression(labelCol=\"HOURLYWindSpeed\", featuresCol='features', maxIter=100, regParam=0.0, elasticNetParam=0.0)\npipeline = Pipeline(stages=[vectorAssembler, normalizer,lr])\nmodel = pipeline.fit(df_train)\nprediction = model.transform(df_test)\nregression_metrics(prediction)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now we\u2019ll try a Gradient Boosted Tree Regressor"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "RMSE on test data = 5.12173\n"
                }
            ],
            "source": "#GBT1\n\nfrom pyspark.ml.regression import GBTRegressor\ngbt = GBTRegressor(labelCol=\"HOURLYWindSpeed\", maxIter=100)\npipeline = Pipeline(stages=[vectorAssembler, normalizer,gbt])\nmodel = pipeline.fit(df_train)\nprediction = model.transform(df_test)\nregression_metrics(prediction)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now let\u2019s switch gears. Previously, we tried to predict HOURLYWindSpeed, but now we predict HOURLYWindDirection. In order to turn this into a classification problem we discretize the value using the Bucketizer. The new feature is called HOURLYWindDirectionBucketized."
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml.feature import Bucketizer, OneHotEncoder\nbucketizer = Bucketizer(splits=[ 0, 180, float('Inf') ],inputCol=\"HOURLYWindDirection\", outputCol=\"HOURLYWindDirectionBucketized\")\nencoder = OneHotEncoder(inputCol=\"HOURLYWindDirectionBucketized\", outputCol=\"HOURLYWindDirectionOHE\")\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Again, we define a function in order to assess how we perform. Here we just use the accuracy measure which gives us the fraction of correctly classified examples. Again, 0 is bad, 1 is good."
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": "def classification_metrics(prediction):\n    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n    mcEval = MulticlassClassificationEvaluator().setMetricName(\"accuracy\") .setPredictionCol(\"prediction\").setLabelCol(\"HOURLYWindDirectionBucketized\")\n    accuracy = mcEval.evaluate(prediction)\n    print(\"Accuracy on test data = %g\" % accuracy)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Again, for baselining we use LogisticRegression."
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Accuracy on test data = 0.692922\n"
                }
            ],
            "source": "#LGReg1\n\nfrom pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression(labelCol=\"HOURLYWindDirectionBucketized\", maxIter=10)\n#,\"ELEVATION\",\"HOURLYStationPressure\",\"HOURLYPressureTendency\",\"HOURLYPrecip\"\n\nvectorAssembler = VectorAssembler(inputCols=[\"HOURLYWindSpeed\",\"HOURLYDRYBULBTEMPC\"],\n                                  outputCol=\"features\")\n\npipeline = Pipeline(stages=[bucketizer,vectorAssembler,normalizer,lr])\nmodel = pipeline.fit(df_train)\nprediction = model.transform(df_test)\nclassification_metrics(prediction)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let\u2019s try some other Algorithms and see if model performance increases. It\u2019s also important to tweak other parameters like parameters of individual algorithms (e.g. number of trees for RandomForest) or parameters in the feature engineering pipeline, e.g. train/test split ratio, normalization, bucketing, \u2026"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Accuracy on test data = 0.721005\n"
                }
            ],
            "source": "#RF1\n\nfrom pyspark.ml.classification import RandomForestClassifier\nrf = RandomForestClassifier(labelCol=\"HOURLYWindDirectionBucketized\", numTrees=30)\n\nvectorAssembler = VectorAssembler(inputCols=[\"HOURLYWindSpeed\",\"HOURLYDRYBULBTEMPC\",\"ELEVATION\",\"HOURLYStationPressure\",\"HOURLYPressureTendency\",\"HOURLYPrecip\"],\n                                  outputCol=\"features\")\n\npipeline = Pipeline(stages=[bucketizer,vectorAssembler,normalizer,rf])\nmodel = pipeline.fit(df_train)\nprediction = model.transform(df_test)\nclassification_metrics(prediction)"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Accuracy on test data = 0.73242\n"
                }
            ],
            "source": "#GBT2\n\nfrom pyspark.ml.classification import GBTClassifier\ngbt = GBTClassifier(labelCol=\"HOURLYWindDirectionBucketized\", maxIter=100)\n\nvectorAssembler = VectorAssembler(inputCols=[\"HOURLYWindSpeed\",\"HOURLYDRYBULBTEMPC\",\"ELEVATION\",\"HOURLYStationPressure\",\"HOURLYPressureTendency\",\"HOURLYPrecip\"],\n                                  outputCol=\"features\")\n\npipeline = Pipeline(stages=[bucketizer,vectorAssembler,normalizer,gbt])\nmodel = pipeline.fit(df_train)\nprediction = model.transform(df_test)\nclassification_metrics(prediction)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark",
            "language": "python3",
            "name": "python36"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}